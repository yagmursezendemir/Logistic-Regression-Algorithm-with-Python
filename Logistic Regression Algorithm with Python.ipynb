{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 32','id'],axis = 1,inplace = True)\n",
    "data.diagnosis = [1 if each == 'M' else 0 for each in data.diagnosis]\n",
    "#print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.diagnosis.values\n",
    "x_data = data.drop(['diagnosis'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (x_data - np.min(x_data))/(np.max(x_data)-np.min(x_data)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter initialize and sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_and_bias(dimension):\n",
    "    w = np.full((dimension,1),0.01)\n",
    "    b = 0.0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    y_head = 1/(1+np.exp(-z))\n",
    "    return y_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (30, 455)\n",
      "x_test:  (30, 114)\n",
      "y_train:  (455,)\n",
      "y_test:  (114,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state=42)\n",
    "\n",
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "print(\"x_train: \",x_train.shape)\n",
    "print(\"x_test: \",x_test.shape)\n",
    "print(\"y_train: \",y_train.shape)\n",
    "print(\"y_test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward_propagation(w,b,x_train,y_train):\n",
    "    # forward propagation\n",
    "    z = np.dot(w.T,x_train) + b\n",
    "    y_head = sigmoid(z)\n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n",
    "    cost = (np.sum(loss))/x_train.shape[1]     \n",
    "    \n",
    "    # backward propagation\n",
    "    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1] # x_train.shape[1]  is for scaling\n",
    "    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]                 # x_train.shape[1]  is for scaling\n",
    "    gradients = {\"derivative_weight\": derivative_weight, \"derivative_bias\": derivative_bias}\n",
    "    \n",
    "    return cost,gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w, b, x_train, y_train, learning_rate,number_of_iterarion):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "    \n",
    "    # updating(learning) parameters is number_of_iterarion times\n",
    "    for i in range(number_of_iterarion):\n",
    "        # make forward and backward propagation and find cost and gradients\n",
    "        cost,gradients = forward_backward_propagation(w,b,x_train,y_train)\n",
    "        cost_list.append(cost)\n",
    "        # lets update\n",
    "        w = w - learning_rate * gradients[\"derivative_weight\"]\n",
    "        b = b - learning_rate * gradients[\"derivative_bias\"]\n",
    "        if i % 10 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "            \n",
    "    # updating(learn) parameters weights and bias\n",
    "    parameters = {\"weight\": w,\"bias\": b}\n",
    "    plt.plot(index,cost_list2)\n",
    "    plt.xticks(index,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w,b,x_test):\n",
    "    # x_test is a input for forward propagation\n",
    "    z = sigmoid(np.dot(w.T,x_test)+b)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n",
    "    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0,i]<= 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.692977\n",
      "Cost after iteration 10: 0.499667\n",
      "Cost after iteration 20: 0.406616\n",
      "Cost after iteration 30: 0.351936\n",
      "Cost after iteration 40: 0.315762\n",
      "Cost after iteration 50: 0.289862\n",
      "Cost after iteration 60: 0.270257\n",
      "Cost after iteration 70: 0.254795\n",
      "Cost after iteration 80: 0.242214\n",
      "Cost after iteration 90: 0.231722\n",
      "Cost after iteration 100: 0.222796\n",
      "Cost after iteration 110: 0.215080\n",
      "Cost after iteration 120: 0.208317\n",
      "Cost after iteration 130: 0.202324\n",
      "Cost after iteration 140: 0.196961\n",
      "Cost after iteration 150: 0.192121\n",
      "Cost after iteration 160: 0.187722\n",
      "Cost after iteration 170: 0.183698\n",
      "Cost after iteration 180: 0.179997\n",
      "Cost after iteration 190: 0.176577\n",
      "Cost after iteration 200: 0.173402\n",
      "Cost after iteration 210: 0.170443\n",
      "Cost after iteration 220: 0.167676\n",
      "Cost after iteration 230: 0.165080\n",
      "Cost after iteration 240: 0.162638\n",
      "Cost after iteration 250: 0.160334\n",
      "Cost after iteration 260: 0.158155\n",
      "Cost after iteration 270: 0.156091\n",
      "Cost after iteration 280: 0.154131\n",
      "Cost after iteration 290: 0.152266\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 96.49122807017544 %\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(x_train, y_train, x_test, y_test, learning_rate ,  num_iterations):\n",
    "    # initialize\n",
    "    dimension =  x_train.shape[0]  # that is 30\n",
    "    w,b = initialize_weights_and_bias(dimension)\n",
    "    \n",
    "    parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate,num_iterations)\n",
    "    \n",
    "    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n",
    "\n",
    "    # Print test Errors\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    \n",
    "logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 1, num_iterations = 300)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
